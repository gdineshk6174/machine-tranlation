{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/ita.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport numpy as np\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(pd.read_csv('../input/ita.txt', sep = '\\t', header = None), test_size = 0.10)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns = ['english', 'italian']\nprint (train.shape)\nprint (test.shape)\ntrain.head()","execution_count":4,"outputs":[{"output_type":"stream","text":"(289289, 2)\n(32144, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                           english                                italian\n133839    We can't leave Tom here.     Noi non possiamo lasciare qui Tom.\n146675   Tom got on the wrong bus.   Tom è salito sull'autobus sbagliato.\n157856  I'm up to my neck in work.  Io ne ho fino al collo con il lavoro.\n131707    Tom can understand Mary.         Tom riesce a comprendere Mary.\n28763             Tom called back.                     Tom ha richiamato.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>italian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>133839</td>\n      <td>We can't leave Tom here.</td>\n      <td>Noi non possiamo lasciare qui Tom.</td>\n    </tr>\n    <tr>\n      <td>146675</td>\n      <td>Tom got on the wrong bus.</td>\n      <td>Tom è salito sull'autobus sbagliato.</td>\n    </tr>\n    <tr>\n      <td>157856</td>\n      <td>I'm up to my neck in work.</td>\n      <td>Io ne ho fino al collo con il lavoro.</td>\n    </tr>\n    <tr>\n      <td>131707</td>\n      <td>Tom can understand Mary.</td>\n      <td>Tom riesce a comprendere Mary.</td>\n    </tr>\n    <tr>\n      <td>28763</td>\n      <td>Tom called back.</td>\n      <td>Tom ha richiamato.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic text preprocessing to both 'english' and 'italian' text \n# converting all text to lowercase and removing unneccesary characters\ntrain['eng_lower'] = train.english.str.lower()\ntrain['eng_no_punc'] = train['eng_lower'].str.replace('[^\\w\\s]','')\n\n'''\nwe add 'start' and 'end' at the begining and ending off the italian text so have some indecation so that our decoder\ncan tell where to start and where to stop\n'''\ntrain['ita_lower'] = train['italian'].str.lower()\ntrain['ita_no_punc'] = '_start_'+' '+train['ita_lower'].str.replace('[^\\w\\s]','')+' '+'_end_'\n\n\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                           english                                italian  \\\n133839    We can't leave Tom here.     Noi non possiamo lasciare qui Tom.   \n146675   Tom got on the wrong bus.   Tom è salito sull'autobus sbagliato.   \n157856  I'm up to my neck in work.  Io ne ho fino al collo con il lavoro.   \n131707    Tom can understand Mary.         Tom riesce a comprendere Mary.   \n28763             Tom called back.                     Tom ha richiamato.   \n\n                         eng_lower               eng_no_punc  \\\n133839    we can't leave tom here.    we cant leave tom here   \n146675   tom got on the wrong bus.  tom got on the wrong bus   \n157856  i'm up to my neck in work.  im up to my neck in work   \n131707    tom can understand mary.   tom can understand mary   \n28763             tom called back.           tom called back   \n\n                                    ita_lower  \\\n133839     noi non possiamo lasciare qui tom.   \n146675   tom è salito sull'autobus sbagliato.   \n157856  io ne ho fino al collo con il lavoro.   \n131707         tom riesce a comprendere mary.   \n28763                      tom ha richiamato.   \n\n                                              ita_no_punc  \n133839    _start_ noi non possiamo lasciare qui tom _end_  \n146675   _start_ tom è salito sullautobus sbagliato _end_  \n157856  _start_ io ne ho fino al collo con il lavoro _...  \n131707        _start_ tom riesce a comprendere mary _end_  \n28763                     _start_ tom ha richiamato _end_  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>italian</th>\n      <th>eng_lower</th>\n      <th>eng_no_punc</th>\n      <th>ita_lower</th>\n      <th>ita_no_punc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>133839</td>\n      <td>We can't leave Tom here.</td>\n      <td>Noi non possiamo lasciare qui Tom.</td>\n      <td>we can't leave tom here.</td>\n      <td>we cant leave tom here</td>\n      <td>noi non possiamo lasciare qui tom.</td>\n      <td>_start_ noi non possiamo lasciare qui tom _end_</td>\n    </tr>\n    <tr>\n      <td>146675</td>\n      <td>Tom got on the wrong bus.</td>\n      <td>Tom è salito sull'autobus sbagliato.</td>\n      <td>tom got on the wrong bus.</td>\n      <td>tom got on the wrong bus</td>\n      <td>tom è salito sull'autobus sbagliato.</td>\n      <td>_start_ tom è salito sullautobus sbagliato _end_</td>\n    </tr>\n    <tr>\n      <td>157856</td>\n      <td>I'm up to my neck in work.</td>\n      <td>Io ne ho fino al collo con il lavoro.</td>\n      <td>i'm up to my neck in work.</td>\n      <td>im up to my neck in work</td>\n      <td>io ne ho fino al collo con il lavoro.</td>\n      <td>_start_ io ne ho fino al collo con il lavoro _...</td>\n    </tr>\n    <tr>\n      <td>131707</td>\n      <td>Tom can understand Mary.</td>\n      <td>Tom riesce a comprendere Mary.</td>\n      <td>tom can understand mary.</td>\n      <td>tom can understand mary</td>\n      <td>tom riesce a comprendere mary.</td>\n      <td>_start_ tom riesce a comprendere mary _end_</td>\n    </tr>\n    <tr>\n      <td>28763</td>\n      <td>Tom called back.</td>\n      <td>Tom ha richiamato.</td>\n      <td>tom called back.</td>\n      <td>tom called back</td>\n      <td>tom ha richiamato.</td>\n      <td>_start_ tom ha richiamato _end_</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 5000\nmax_len = 35\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word embedding\ntok1 = tf.keras.preprocessing.text.Tokenizer(num_words = max_features)\ntok1.fit_on_texts(list(train['eng_no_punc']))\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_train_eng = tok1.texts_to_sequences(list(train['eng_no_punc']))\ntf_train_eng = tf.keras.preprocessing.sequence.pad_sequences(tf_train_eng, maxlen = max_len)\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tok2 = tf.keras.preprocessing.text.Tokenizer(num_words = max_features, filters = '*')\ntok2.fit_on_texts(list(train['ita_no_punc']))\ntf_train_ita = tok2.texts_to_sequences(list(train['ita_no_punc']))\ntf_train_ita = tf.keras.preprocessing.sequence.pad_sequences(tf_train_ita, maxlen = max_len, padding = 'post')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining model inputs and outputs for ecoder and decoder\nencoder_input_data = tf_train_eng\ndoc_length = encoder_input_data.shape[1]\nprint (f'shape of encoder input:{encoder_input_data.shape}')\n\n# decoder\nvectorized_italian = tf_train_ita\n# for decoder input we dont need last word as it for prediction\ndecoder_input_data = vectorized_italian[:,:-1]\n# decoder target data is 1 time step ahead from 'decoder inputdata' \ndecoder_target_data = vectorized_italian[:,1:]\n\nprint (f'shape of decoder input data:{decoder_input_data.shape}')\nprint (f'shape of decder target data:{decoder_target_data.shape}')","execution_count":11,"outputs":[{"output_type":"stream","text":"shape of encoder input:(289289, 35)\nshape of decoder input data:(289289, 34)\nshape of decder target data:(289289, 34)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size_encoder = len(tok1.word_index)+1\nvocab_size_decoder = len(tok1.word_index)+1","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model atchitecture\nlatent_dim = 40\n\n# encoder model\nencoder_inputs = tf.keras.Input(shape = (doc_length,), name= 'Encoder-Input')\n# word embedding for encoder\nx=tf.keras.layers.Embedding(vocab_size_encoder,latent_dim,name='Body-word-embedding',mask_zero=False)(encoder_inputs)\n# batch normalization\nx = tf.keras.layers.BatchNormalization(name = 'Encoder-Batchnorm-1')(x)\n# we need only hidden state of the encoder we dont need the output\n_,state_h = tf.keras.layers.GRU(latent_dim, return_state = True, name = 'Encoder-last-gru')(x)\n# encoder model\nencoder_model = tf.keras.Model(inputs = encoder_inputs, outputs = state_h, name = 'Encoder-model')\nseq2seq_encoder_out = encoder_model(encoder_inputs)\n\n# decoder model\ndecoder_inputs = tf.keras.Input(shape = (None,), name = 'Decoder-input')\n# word embedding for decoder italian\ndec_emb=tf.keras.layers.Embedding(vocab_size_decoder,latent_dim,name='Decoder-word-embedding',mask_zero=False)(decoder_inputs)\n#batch normalization\ndec_bn = tf.keras.layers.BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\ndecoder_gru = tf.keras.layers.GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\ndecoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)  \nx = tf.keras.layers.BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n\n# Dense layer for prediction\ndecoder_dense = tf.keras.layers.Dense(vocab_size_decoder, activation='softmax', name='Final-Output-Dense')\ndecoder_outputs = decoder_dense(x)\n \n# Seq2Seq Model \n\nseq2seq_Model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\nseq2seq_Model.compile(optimizer=tf.keras.optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_Model.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nDecoder-input (InputLayer)      [(None, None)]       0                                            \n__________________________________________________________________________________________________\nDecoder-word-embedding (Embeddi (None, None, 40)     526600      Decoder-input[0][0]              \n__________________________________________________________________________________________________\nEncoder-Input (InputLayer)      [(None, 35)]         0                                            \n__________________________________________________________________________________________________\nDecoder-Batchnorm-1 (BatchNorma (None, None, 40)     160         Decoder-word-embedding[0][0]     \n__________________________________________________________________________________________________\nEncoder-model (Model)           (None, 40)           536480      Encoder-Input[0][0]              \n__________________________________________________________________________________________________\nDecoder-GRU (GRU)               [(None, None, 40), ( 9720        Decoder-Batchnorm-1[0][0]        \n                                                                 Encoder-model[1][0]              \n__________________________________________________________________________________________________\nDecoder-Batchnorm-2 (BatchNorma (None, None, 40)     160         Decoder-GRU[0][0]                \n__________________________________________________________________________________________________\nFinal-Output-Dense (Dense)      (None, None, 13165)  539765      Decoder-Batchnorm-2[0][0]        \n==================================================================================================\nTotal params: 1,612,885\nTrainable params: 1,612,645\nNon-trainable params: 240\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1200\nepochs = 15\nhistory = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n          batch_size=batch_size,  epochs=epochs,  validation_split=0.12) ","execution_count":15,"outputs":[{"output_type":"stream","text":"Train on 254574 samples, validate on 34715 samples\nEpoch 1/15\n254574/254574 [==============================] - 115s 451us/sample - loss: 4.5990 - val_loss: 3.3507\nEpoch 2/15\n254574/254574 [==============================] - 111s 437us/sample - loss: 0.9452 - val_loss: 4.8158\nEpoch 3/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.6687 - val_loss: 2.9973\nEpoch 4/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.5401 - val_loss: 0.6266\nEpoch 5/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.4584 - val_loss: 0.4686\nEpoch 6/15\n254574/254574 [==============================] - 111s 437us/sample - loss: 0.4019 - val_loss: 0.4151\nEpoch 7/15\n254574/254574 [==============================] - 111s 435us/sample - loss: 0.3625 - val_loss: 0.3717\nEpoch 8/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.3334 - val_loss: 0.3487\nEpoch 9/15\n254574/254574 [==============================] - 112s 439us/sample - loss: 0.3118 - val_loss: 0.3263\nEpoch 10/15\n254574/254574 [==============================] - 112s 439us/sample - loss: 0.2945 - val_loss: 0.3153\nEpoch 11/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.2807 - val_loss: 0.3095\nEpoch 12/15\n254574/254574 [==============================] - 112s 438us/sample - loss: 0.2695 - val_loss: 0.3000\nEpoch 13/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.2601 - val_loss: 0.2955\nEpoch 14/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.2521 - val_loss: 0.2841\nEpoch 15/15\n254574/254574 [==============================] - 111s 436us/sample - loss: 0.2454 - val_loss: 0.2787\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_Model1 = seq2seq_Model","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text = ['where is this restaurant?']","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tok1.fit_on_texts(test_text)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_tokenized = tok1.texts_to_sequences(test_text)\nraw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=max_len)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"body_encoding = encoder_model.predict(raw_tokenized)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_dim = seq2seq_Model.get_layer('Decoder-word-embedding').output_shape[-1]","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_inputs = seq2seq_Model.get_layer('Decoder-input').input\ndec_emb = seq2seq_Model.get_layer('Decoder-word-embedding')(decoder_inputs)\ndec_bn = seq2seq_Model.get_layer('Decoder-Batchnorm-1')(dec_emb)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_inference_state_input = tf.keras.Input(shape=(latent_dim,), name='hidden_state_input')\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_out, gru_state_out = seq2seq_Model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dec_bn2 = seq2seq_Model.get_layer('Decoder-Batchnorm-2')(gru_out)\ndense_out = seq2seq_Model.get_layer('Final-Output-Dense')(dec_bn2)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_model = tf.keras.Model([decoder_inputs, gru_inference_state_input],\n                          [dense_out, gru_state_out])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_body_encoding = body_encoding","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_value = np.array(tok2.word_index['_start_']).reshape(1, 1)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_value","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"array([[1]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_sentence = []\nstop_condition = False","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary_inv = dict((v, k) for k, v in tok2.word_index.items())\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwhile not stop_condition:\n    preds, st = decoder_model.predict([state_value, body_encoding])\n\n    pred_idx = np.argmax(preds[:, :, 2:]) + 2\n    pred_word_str = vocabulary_inv[pred_idx]\n    #print(pred_idx)\n    print(pred_word_str)\n    if pred_word_str == '_end_' or len(decoded_sentence) >= max_len:\n        stop_condition = True\n        break\n    decoded_sentence.append(pred_word_str)\n\n    body_encoding = st\n    state_value = np.array(pred_idx).reshape(1, 1)\n\n","execution_count":32,"outputs":[{"output_type":"stream","text":"dovè\nquesto\nristorante\n_end_\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('sample text is %s' % test_text)\ntranslated_text = ' '.join(decoded_sentence)\nprint ('-----------------------')\nprint ('translated sample text is: \"%s\"' %translated_text)","execution_count":33,"outputs":[{"output_type":"stream","text":"sample text is ['where is this restaurant?']\n-----------------------\ntranslated sample text is: \"dovè questo ristorante\"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"when we translate \"**where is this restaurant?**\" in google-translate we get \"**dov'è questo ristorante?**\"<br> and when we translated the sentence we got \"**dovè questo ristorante**\" which means \"**where this restaurant is**\"...<br>the difference is \"**dov'è**\" from google translate means \"**where is it**\" ,while \"**dovè**\" from this model's translation mean \"**where is**\". <br> we can see the model that can translate the essence of the sample text correctly, well since this a simple model i think it did a good job. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}